{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from src.utils import MappingData\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3638892, 83)\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(\"../data\", \"treatments_2017-2020_preprocessed\")\n",
    "\n",
    "df = pd.read_parquet(path + \".parquet\")\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building features and encoding categorical data \n",
    "\n",
    "encode ordinal variable using categoircal and factorize functions to ensure an order in the feature's categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGE : The age of the client at Admission\n",
    "categories = [\n",
    "    \"12-17 years old\",\n",
    "    \"18-29 years old\",\n",
    "    \"30-39 years old\",\n",
    "    \"40-49 years old\",\n",
    "    \"50-64 years old\",\n",
    "    \"65+ years old\",\n",
    "]\n",
    "df[\"AGE\"] = pd.Categorical(df[\"AGE\"], categories=categories, ordered=True)\n",
    "labels, categories = pd.factorize(df[\"AGE\"], sort=True)\n",
    "df[\"AGE\"] = labels\n",
    "\n",
    "\n",
    "# EDUC : The clientâ€™s level of education\n",
    "categories = [\n",
    "    \"No schooling\",\n",
    "    \"Grades 9-11\",\n",
    "    \"Grade 12\",\n",
    "    \"1-3 years of college\",\n",
    "    \"4 years of college, BA/BS, or more\",\n",
    "]\n",
    "df[\"EDUC\"] = pd.Categorical(df[\"EDUC\"], categories=categories, ordered=True)\n",
    "labels, categories = pd.factorize(df[\"EDUC\"], sort=True)\n",
    "df[\"EDUC\"] = labels.astype(int)\n",
    "\n",
    "\n",
    "# ARRESTS : Arrests of client made 30 days prior to admission.\n",
    "categories = [\"None\", \"Once\", \"Two or more times\"]\n",
    "df[\"ARRESTS\"] = pd.Categorical(df[\"ARRESTS\"], categories=categories, ordered=True)\n",
    "labels, categories = pd.factorize(df[\"ARRESTS\"], sort=True)\n",
    "df[\"ARRESTS\"] = labels\n",
    "\n",
    "\n",
    "# DAYWAIT : Indicates the number of days from the first contact or request for a substance use\n",
    "#  treatment service until the client was admitted and the first clinical substance use treatment service was provided.\n",
    "categories = [\"0-14 days\", \"15-30 days\", \"31+ days\"]\n",
    "df[\"DAYWAIT\"] = pd.Categorical(df[\"DAYWAIT\"], categories=categories, ordered=True)\n",
    "labels, categories = pd.factorize(df[\"DAYWAIT\"], sort=True)\n",
    "df[\"DAYWAIT\"] = labels\n",
    "\n",
    "\n",
    "# FRSTUSE1 : this is the age of first intoxication\n",
    "categories = [\n",
    "    \"11 years and under\",\n",
    "    \"12-17 years\",\n",
    "    \"18-24 years\",\n",
    "    \"25-29 years\",\n",
    "    \"30 years and older\",\n",
    "]\n",
    "df[\"FRSTUSE1\"] = pd.Categorical(df[\"FRSTUSE1\"], categories=categories, ordered=True)\n",
    "labels, categories = pd.factorize(df[\"FRSTUSE1\"], sort=True)\n",
    "df[\"FRSTUSE1\"] = labels\n",
    "\n",
    "\n",
    "# NUM_SUBS : no of substances taken by a client\n",
    "categories = [\"Zero sub\", \"One sub\", \"Two sub\", \"Three sub\"]\n",
    "df[\"NUM_SUBS\"] = pd.Categorical(df[\"NUM_SUBS\"], categories=categories, ordered=True)\n",
    "labels, categories = pd.factorize(df[\"NUM_SUBS\"], sort=True)\n",
    "df[\"NUM_SUBS\"] = labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Selecting only thise columns which will be used further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only features which we will use further\n",
    "columns_of_imp = [\n",
    "    \"AGE\",\n",
    "    \"GENDER\",\n",
    "    \"RACE\",\n",
    "    \"ETHNIC\",\n",
    "    \"MARSTAT\",\n",
    "    \"EDUC\",\n",
    "    \"EMPLOY\",\n",
    "    \"PREG\",\n",
    "    \"VET\",\n",
    "    \"LIVARAG\",\n",
    "    \"PRIMINC\",\n",
    "    \"ARRESTS\",\n",
    "    \"DIVISION\",\n",
    "    \"SERVICES\",\n",
    "    \"DAYWAIT\",\n",
    "    \"PSOURCE\",\n",
    "    \"SUB1\",\n",
    "    \"FREQ1\",\n",
    "    \"FRSTUSE1\",\n",
    "    \"PSYPROB\",\n",
    "    \"HLTHINS\",\n",
    "    \"FREQ_ATND_SELF_HELP\",\n",
    "    \"NOPRIOR\",\n",
    "    \"NUM_SUBS\",\n",
    "]\n",
    "df = df[columns_of_imp]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dropping columns with > 50% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Column  % missing\n",
      "0                   AGE   0.000000\n",
      "1                GENDER   0.038693\n",
      "2                  RACE   1.326805\n",
      "3                ETHNIC   1.601367\n",
      "4               MARSTAT  15.207569\n",
      "5                  EDUC   0.000000\n",
      "6                EMPLOY   1.554402\n",
      "7                  PREG  66.711680\n",
      "8                   VET   5.518878\n",
      "9               LIVARAG   2.470615\n",
      "10              PRIMINC  37.659898\n",
      "11              ARRESTS   0.000000\n",
      "12             DIVISION   0.000000\n",
      "13             SERVICES   0.000000\n",
      "14              DAYWAIT   0.000000\n",
      "15              PSOURCE   1.588066\n",
      "16                 SUB1   0.656271\n",
      "17                FREQ1   6.244483\n",
      "18             FRSTUSE1   0.000000\n",
      "19              PSYPROB   9.670801\n",
      "20              HLTHINS  57.529435\n",
      "21  FREQ_ATND_SELF_HELP  14.572375\n",
      "22              NOPRIOR   0.000000\n",
      "23             NUM_SUBS   0.000000\n",
      "Columns dropped due to too many missing values : ['PREG', 'HLTHINS']\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns with more than 50% values\n",
    "df_missing_perc = pd.DataFrame(df.isnull().sum() / df.shape[0] * 100).reset_index()\n",
    "df_missing_perc.columns = [\"Column\", \"% missing\"]\n",
    "print(df_missing_perc)\n",
    "columns_50perc_missing = list(\n",
    "    df_missing_perc[df_missing_perc[\"% missing\"] > 50.0][\"Column\"].values\n",
    ")\n",
    "print(\n",
    "    \"Columns dropped due to too many missing values : {}\".format(columns_50perc_missing)\n",
    ")\n",
    "df = df.drop(columns_50perc_missing, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Imputing missing values with SimpleImputer with mode as the filling criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values\n",
    "imputer = SimpleImputer(missing_values=None, strategy=\"most_frequent\")\n",
    "df_transformed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns).astype(\n",
    "    df.dtypes.to_dict()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving the data which will be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = os.path.join(\"../data\", \"treatments_2017-2020\" + \"_train\" + \".parquet\")\n",
    "df_transformed.to_parquet(path_to_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
